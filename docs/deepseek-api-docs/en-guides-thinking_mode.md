::: {#__docusaurus}
::: {role="region" aria-label="Skip to main content"}
[Skip to main
content](#__docusaurus_skipToContent_fallback){.skipToContent_xSgN}
:::

::: navbar__inner
::: navbar__items
![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAiIGhlaWdodD0iMzAiIHZpZXdib3g9IjAgMCAzMCAzMCIgYXJpYS1oaWRkZW49InRydWUiPjxwYXRoIHN0cm9rZT0iY3VycmVudENvbG9yIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1taXRlcmxpbWl0PSIxMCIgc3Ryb2tlLXdpZHRoPSIyIiBkPSJNNCA3aDIyTTQgMTVoMjJNNCAyM2gyMiI+PC9wYXRoPjwvc3ZnPg==)

[](/){.navbar__brand}

::: navbar__logo
![DeepSeek API Docs
Logo](https://cdn.deepseek.com/platform/favicon.png){.themedComponent_EBr5
.themedComponent--light_FDat}![DeepSeek API Docs
Logo](https://cdn.deepseek.com/platform/favicon.png){.themedComponent_EBr5
.themedComponent--dark_NU8c}
:::

**DeepSeek API Docs**
:::

::: {.navbar__items .navbar__items--right}
::: {.navbar__item .dropdown .dropdown--hoverable .dropdown--right}
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIHdpZHRoPSIyMCIgaGVpZ2h0PSIyMCIgYXJpYS1oaWRkZW49InRydWUiIGNsYXNzPSJpY29uTGFuZ3VhZ2VfQjZYMSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMTIuODcgMTUuMDdsLTIuNTQtMi41MS4wMy0uMDNjMS43NC0xLjk0IDIuOTgtNC4xNyAzLjcxLTYuNTNIMTdWNGgtN1YySDh2MkgxdjEuOTloMTEuMTdDMTEuNSA3LjkyIDEwLjQ0IDkuNzUgOSAxMS4zNSA4LjA3IDEwLjMyIDcuMyA5LjE5IDYuNjkgOGgtMmMuNzMgMS42MyAxLjczIDMuMTcgMi45OCA0LjU2bC01LjA5IDUuMDJMNCAxOWw1LTUgMy4xMSAzLjExLjc2LTIuMDR6TTE4LjUgMTBoLTJMMTIgMjJoMmwxLjEyLTNoNC43NUwyMSAyMmgybC00LjUtMTJ6bS0yLjYyIDdsMS42Mi00LjMzTDE5LjEyIDE3aC0zLjI0eiI+PC9wYXRoPjwvc3ZnPg==){.iconLanguage_B6X1}English](#){.navbar__link
aria-haspopup="true" aria-expanded="false" role="button"}

-   [English](/guides/thinking_mode){.dropdown__link
    .dropdown__link--active target="_self" rel="noopener noreferrer"
    lang="en"}
-   [中文（中国）](/zh-cn/guides/thinking_mode){.dropdown__link
    target="_self" rel="noopener noreferrer" lang="zh-cn"}
:::

[DeepSeek
Platform![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://platform.deepseek.com/){.navbar__item
.navbar__link target="_blank" rel="noopener noreferrer"}

::: {.toggle_SQQt .colorModeToggle_ulqQ}
![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgY2xhc3M9ImxpZ2h0VG9nZ2xlSWNvbl9KQ1FOIj48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xMiw5YzEuNjUsMCwzLDEuMzUsMywzcy0xLjM1LDMtMywzcy0zLTEuMzUtMy0zUzEwLjM1LDksMTIsOSBNMTIsN2MtMi43NiwwLTUsMi4yNC01LDVzMi4yNCw1LDUsNXM1LTIuMjQsNS01IFMxNC43Niw3LDEyLDdMMTIsN3ogTTIsMTNsMiwwYzAuNTUsMCwxLTAuNDUsMS0xcy0wLjQ1LTEtMS0xbC0yLDBjLTAuNTUsMC0xLDAuNDUtMSwxUzEuNDUsMTMsMiwxM3ogTTIwLDEzbDIsMGMwLjU1LDAsMS0wLjQ1LDEtMSBzLTAuNDUtMS0xLTFsLTIsMGMtMC41NSwwLTEsMC40NS0xLDFTMTkuNDUsMTMsMjAsMTN6IE0xMSwydjJjMCwwLjU1LDAuNDUsMSwxLDFzMS0wLjQ1LDEtMVYyYzAtMC41NS0wLjQ1LTEtMS0xUzExLDEuNDUsMTEsMnogTTExLDIwdjJjMCwwLjU1LDAuNDUsMSwxLDFzMS0wLjQ1LDEtMXYtMmMwLTAuNTUtMC40NS0xLTEtMUMxMS40NSwxOSwxMSwxOS40NSwxMSwyMHogTTUuOTksNC41OGMtMC4zOS0wLjM5LTEuMDMtMC4zOS0xLjQxLDAgYy0wLjM5LDAuMzktMC4zOSwxLjAzLDAsMS40MWwxLjA2LDEuMDZjMC4zOSwwLjM5LDEuMDMsMC4zOSwxLjQxLDBzMC4zOS0xLjAzLDAtMS40MUw1Ljk5LDQuNTh6IE0xOC4zNiwxNi45NSBjLTAuMzktMC4zOS0xLjAzLTAuMzktMS40MSwwYy0wLjM5LDAuMzktMC4zOSwxLjAzLDAsMS40MWwxLjA2LDEuMDZjMC4zOSwwLjM5LDEuMDMsMC4zOSwxLjQxLDBjMC4zOS0wLjM5LDAuMzktMS4wMywwLTEuNDEgTDE4LjM2LDE2Ljk1eiBNMTkuNDIsNS45OWMwLjM5LTAuMzksMC4zOS0xLjAzLDAtMS40MWMtMC4zOS0wLjM5LTEuMDMtMC4zOS0xLjQxLDBsLTEuMDYsMS4wNmMtMC4zOSwwLjM5LTAuMzksMS4wMywwLDEuNDEgczEuMDMsMC4zOSwxLjQxLDBMMTkuNDIsNS45OXogTTcuMDUsMTguMzZjMC4zOS0wLjM5LDAuMzktMS4wMywwLTEuNDFjLTAuMzktMC4zOS0xLjAzLTAuMzktMS40MSwwbC0xLjA2LDEuMDYgYy0wLjM5LDAuMzktMC4zOSwxLjAzLDAsMS40MXMxLjAzLDAuMzksMS40MSwwTDcuMDUsMTguMzZ6Ij48L3BhdGg+PC9zdmc+){.lightToggleIcon_JCQN}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgY2xhc3M9ImRhcmtUb2dnbGVJY29uX1IzRU4iPjxwYXRoIGZpbGw9ImN1cnJlbnRDb2xvciIgZD0iTTkuMzcsNS41MUM5LjE5LDYuMTUsOS4xLDYuODIsOS4xLDcuNWMwLDQuMDgsMy4zMiw3LjQsNy40LDcuNGMwLjY4LDAsMS4zNS0wLjA5LDEuOTktMC4yN0MxNy40NSwxNy4xOSwxNC45MywxOSwxMiwxOSBjLTMuODYsMC03LTMuMTQtNy03QzUsOS4wNyw2LjgxLDYuNTUsOS4zNyw1LjUxeiBNMTIsM2MtNC45NywwLTksNC4wMy05LDlzNC4wMyw5LDksOXM5LTQuMDMsOS05YzAtMC40Ni0wLjA0LTAuOTItMC4xLTEuMzYgYy0wLjk4LDEuMzctMi41OCwyLjI2LTQuNCwyLjI2Yy0yLjk4LDAtNS40LTIuNDItNS40LTUuNGMwLTEuODEsMC44OS0zLjQyLDIuMjYtNC40QzEyLjkyLDMuMDQsMTIuNDYsMywxMiwzTDEyLDN6Ij48L3BhdGg+PC9zdmc+){.darkToggleIcon_R3EN}
:::

::: navbarSearchContainer_uDFu
:::
:::
:::

::: {.navbar-sidebar__backdrop role="presentation"}
:::

::: {#__docusaurus_skipToContent_fallback .main-wrapper .mainWrapper_O4_m}
::: docsWrapper_mcSy
::: docRoot_Dr47
::: sidebarViewport_VhFV
::: sidebar_pcuX
-   ::: menu__list-item-collapsible
    [Quick Start](/){.menu__link .menu__link--sublist
    .menu__link--sublist-caret aria-expanded="true"}
    :::

    -   [Your First API Call](/){.menu__link tabindex="0"}
    -   [Models & Pricing](/quick_start/pricing){.menu__link
        tabindex="0"}
    -   [The Temperature
        Parameter](/quick_start/parameter_settings){.menu__link
        tabindex="0"}
    -   [Token & Token Usage](/quick_start/token_usage){.menu__link
        tabindex="0"}
    -   [Rate Limit](/quick_start/rate_limit){.menu__link tabindex="0"}
    -   [Error Codes](/quick_start/error_codes){.menu__link
        tabindex="0"}

-   ::: menu__list-item-collapsible
    [News](/news/news251201){.menu__link .menu__link--sublist
    .menu__link--sublist-caret aria-expanded="true"}
    :::

    -   [DeepSeek-V3.2 Release 2025/12/01](/news/news251201){.menu__link
        tabindex="0"}
    -   [DeepSeek-V3.2-Exp Release
        2025/09/29](/news/news250929){.menu__link tabindex="0"}
    -   [DeepSeek V3.1 Update 2025/09/22](/news/news250922){.menu__link
        tabindex="0"}
    -   [DeepSeek V3.1 Release 2025/08/21](/news/news250821){.menu__link
        tabindex="0"}
    -   [DeepSeek-R1-0528 Release
        2025/05/28](/news/news250528){.menu__link tabindex="0"}
    -   [DeepSeek-V3-0324 Release
        2025/03/25](/news/news250325){.menu__link tabindex="0"}
    -   [DeepSeek-R1 Release 2025/01/20](/news/news250120){.menu__link
        tabindex="0"}
    -   [DeepSeek APP 2025/01/15](/news/news250115){.menu__link
        tabindex="0"}
    -   [Introducing DeepSeek-V3 2024/12/26](/news/news1226){.menu__link
        tabindex="0"}
    -   [DeepSeek-V2.5-1210 Release
        2024/12/10](/news/news1210){.menu__link tabindex="0"}
    -   [DeepSeek-R1-Lite Release
        2024/11/20](/news/news1120){.menu__link tabindex="0"}
    -   [DeepSeek-V2.5 Release 2024/09/05](/news/news0905){.menu__link
        tabindex="0"}
    -   [Context Caching is Available
        2024/08/02](/news/news0802){.menu__link tabindex="0"}
    -   [New API Features 2024/07/25](/news/news0725){.menu__link
        tabindex="0"}

-   ::: menu__list-item-collapsible
    [API Reference](/api/deepseek-api){.menu__link .menu__link--sublist
    .menu__link--sublist-caret aria-expanded="false"}
    :::

-   ::: menu__list-item-collapsible
    [API Guides](/guides/thinking_mode){.menu__link .menu__link--sublist
    .menu__link--sublist-caret .menu__link--active aria-expanded="true"}
    :::

    -   [Thinking Mode](/guides/thinking_mode){.menu__link
        .menu__link--active aria-current="page" tabindex="0"}
    -   [Multi-round Conversation](/guides/multi_round_chat){.menu__link
        tabindex="0"}
    -   [Chat Prefix Completion
        (Beta)](/guides/chat_prefix_completion){.menu__link
        tabindex="0"}
    -   [FIM Completion (Beta)](/guides/fim_completion){.menu__link
        tabindex="0"}
    -   [JSON Output](/guides/json_mode){.menu__link tabindex="0"}
    -   [Tool Calls](/guides/tool_calls){.menu__link tabindex="0"}
    -   [Context Caching](/guides/kv_cache){.menu__link tabindex="0"}
    -   [Anthropic API](/guides/anthropic_api){.menu__link tabindex="0"}

-   ::: menu__list-item-collapsible
    [Other
    Resources](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main){.menu__link
    .menu__link--sublist .menu__link--sublist-caret target="_blank"
    rel="noopener noreferrer" aria-expanded="true"}
    :::

    -   [Integrations![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main){.menu__link
        .menuExternalLink_kqFC target="_blank" rel="noopener noreferrer"
        tabindex="0"}
    -   [API Status
        Page![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://status.deepseek.com/){.menu__link
        .menuExternalLink_kqFC target="_blank" rel="noopener noreferrer"
        tabindex="0"}

-   [FAQ](/faq){.menu__link}

-   [Change Log](/updates){.menu__link}
:::
:::

::: {.docMainContainer_SNqp role="main"}
::: {.container .padding-top--md .padding-bottom--lg}
::: row
::: {.col .docItemCol_GEdM}
::: docItemContainer_OUCh
-   [![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJicmVhZGNydW1iSG9tZUljb25fZmJtTSI+PHBhdGggZD0iTTEwIDE5di01aDR2NWMwIC41NS40NSAxIDEgMWgzYy41NSAwIDEtLjQ1IDEtMXYtN2gxLjdjLjQ2IDAgLjY4LS41Ny4zMy0uODdMMTIuNjcgMy42Yy0uMzgtLjM0LS45Ni0uMzQtMS4zNCAwbC04LjM2IDcuNTNjLS4zNC4zLS4xMy44Ny4zMy44N0g1djdjMCAuNTUuNDUgMSAxIDFoM2MuNTUgMCAxLS40NSAxLTF6IiBmaWxsPSJjdXJyZW50Q29sb3IiPjwvcGF0aD48L3N2Zz4=){.breadcrumbHomeIcon_fbmM}](/){.breadcrumbs__link
    aria-label="Home page"}
-   [API Guides]{.breadcrumbs__link}
-   [Thinking Mode]{.breadcrumbs__link itemprop="name"}

::: {.tocCollapsible_lKxX .theme-doc-toc-mobile .tocMobile_kO7c}
On this page
:::

::: {.theme-doc-markdown .markdown}
::: row
::: {.col .col--12}
# Thinking Mode

The DeepSeek model supports the thinking mode: before outputting the
final answer, the model will first output a chain-of-thought reasoning
to improve the accuracy of the final response. You can enable thinking
mode using any of the following methods:

1.  Set the `model` parameter: `"model": "deepseek-reasoner"`

2.  Set the `thinking` parameter: `"thinking": {"type": "enabled"}`

If you are using the OpenAI SDK, when setting `thinking` parameter, you
need to pass the `thinking` parameter within `extra_body`:

::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
response = client.chat.completions.create(
  model="deepseek-chat",
  # ...
  extra_body={"thinking": {"type": "enabled"}}
)
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::

## API Parameters[​](#api-parameters "Direct link to API Parameters"){.hash-link aria-label="Direct link to API Parameters"} {#api-parameters .anchor .anchorWithStickyNavbar_YAqC}

-   **Input**：

    -   `max_tokens`：The maximum output length (including the COT
        part). Default to 32K, maximum to 64K.

-   **Output**：

    -   `reasoning_content`：The content of the CoT，which is at the
        same level as `content` in the output structure. See [API
        Example](#api-example) for details.
    -   `content`: The content of the final answer.
    -   `tool_calls`: The tool calls.

-   **Supported Features**：[Json Output](/guides/json_mode)、[Tool
    Calls](/guides/tool_calls)、[Chat
    Completion](/api/create-chat-completion)、[Chat Prefix Completion
    (Beta)](/guides/chat_prefix_completion)

-   **Not Supported Features**：FIM (Beta)

-   **Not Supported
    Parameters**：`temperature`、`top_p`、`presence_penalty`、`frequency_penalty`、`logprobs`、`top_logprobs`.
    Please note that to ensure compatibility with existing software,
    setting
    `temperature`、`top_p`、`presence_penalty`、`frequency_penalty` will
    not trigger an error but will also have no effect. Setting
    `logprobs`、`top_logprobs` will trigger an error.

## Multi-turn Conversation[​](#multi-turn-conversation "Direct link to Multi-turn Conversation"){.hash-link aria-label="Direct link to Multi-turn Conversation"} {#multi-turn-conversation .anchor .anchorWithStickyNavbar_YAqC}

In each turn of the conversation, the model outputs the CoT
(`reasoning_content`) and the final answer (`content`). In the next turn
of the conversation, the CoT from previous turns is not concatenated
into the context, as illustrated in the following diagram:

::: {align="center"}
![](/img/deepseek_r1_multiround_example_en.jpeg){width="512"}
:::

## API Example[​](#api-example "Direct link to API Example"){.hash-link aria-label="Direct link to API Example"} {#api-example .anchor .anchorWithStickyNavbar_YAqC}

The following code, using Python as an example, demonstrates how to
access the CoT and the final answer, as well as how to conduct
multi-turn conversations. Note that in the code for the new turn of
conversation, only the `content` from the previous turn\'s output is
passed, while the `reasoning_content` is ignored.

::: {.tabs-container .tabList_MtDO}
-   NoStreaming
-   Streaming

::: margin-top--md
::: {.tabItem_a2xS role="tabpanel"}
::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
from openai import OpenAI
client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

# Turn 1
messages = [{"role": "user", "content": "9.11 and 9.8, which is greater?"}]
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=messages
)

reasoning_content = response.choices[0].message.reasoning_content
content = response.choices[0].message.content

# Turn 2
messages.append({'role': 'assistant', 'content': content})
messages.append({'role': 'user', 'content': "How many Rs are there in the word 'strawberry'?"})
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=messages
)
# ...
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::
:::

::: {.tabItem_a2xS role="tabpanel" hidden=""}
::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
from openai import OpenAI
client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

# Turn 1
messages = [{"role": "user", "content": "9.11 and 9.8, which is greater?"}]
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=messages,
    stream=True
)

reasoning_content = ""
content = ""

for chunk in response:
    if chunk.choices[0].delta.reasoning_content:
        reasoning_content += chunk.choices[0].delta.reasoning_content
    else:
        content += chunk.choices[0].delta.content

# Turn 2
messages.append({"role": "assistant", "content": content})
messages.append({'role': 'user', 'content': "How many Rs are there in the word 'strawberry'?"})
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=messages,
    stream=True
)
# ...
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::
:::
:::
:::

## Tool Calls[​](#tool-calls "Direct link to Tool Calls"){.hash-link aria-label="Direct link to Tool Calls"} {#tool-calls .anchor .anchorWithStickyNavbar_YAqC}

DeepSeek model\'s thinking mode now supports tool calls. Before
outputting the final answer, the model can engage in multiple turns of
reasoning and tool calls to improve the quality of the response. The
calling pattern is illustrated below:

::: {align="center"}
![](/img/v3.2_thinking_with_tools_en.jpeg){width="1024"}
:::

-   During the process of answering question 1 (Turn 1.1 - 1.3), the
    model performed multiple turns of thinking + tool calls before
    providing the answer. During this process, the user needs to send
    the reasoning content (`reasoning_content`) back to the API to allow
    the model to continue reasoning.

-   When the next user question begins (Turn 2.1), the previous
    `reasoning_content` should be removed, while keeping other elements
    to send to the API. If `reasoning_content` is retained and sent to
    the API, the API will ignore it.

### Compatibility Notice[​](#compatibility-notice "Direct link to Compatibility Notice"){.hash-link aria-label="Direct link to Compatibility Notice"} {#compatibility-notice .anchor .anchorWithStickyNavbar_YAqC}

Since the tool invocation process in thinking mode requires users to
pass back `reasoning_content` to the API, if your code does not
correctly pass back `reasoning_content`, the API will return a 400
error. Please refer to the sample code below for the correct way.

### Sample Code[​](#sample-code "Direct link to Sample Code"){.hash-link aria-label="Direct link to Sample Code"} {#sample-code .anchor .anchorWithStickyNavbar_YAqC}

Below is a simple sample code for tool calls in thinking mode:

::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
import os
import json
from openai import OpenAI

# The definition of the tools
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_date",
            "description": "Get the current date",
            "parameters": { "type": "object", "properties": {} },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get weather of a location, the user should supply the location and date.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": { "type": "string", "description": "The city name" },
                    "date": { "type": "string", "description": "The date in format YYYY-mm-dd" },
                },
                "required": ["location", "date"]
            },
        }
    },
]

# The mocked version of the tool calls
def get_date_mock():
    return "2025-12-01"

def get_weather_mock(location, date):
    return "Cloudy 7~13°C"

TOOL_CALL_MAP = {
    "get_date": get_date_mock,
    "get_weather": get_weather_mock
}

def clear_reasoning_content(messages):
    for message in messages:
        if hasattr(message, 'reasoning_content'):
            message.reasoning_content = None

def run_turn(turn, messages):
    sub_turn = 1
    while True:
        response = client.chat.completions.create(
            model='deepseek-chat',
            messages=messages,
            tools=tools,
            extra_body={ "thinking": { "type": "enabled" } }
        )
        messages.append(response.choices[0].message)
        reasoning_content = response.choices[0].message.reasoning_content
        content = response.choices[0].message.content
        tool_calls = response.choices[0].message.tool_calls
        print(f"Turn {turn}.{sub_turn}\n{reasoning_content=}\n{content=}\n{tool_calls=}")
        # If there is no tool calls, then the model should get a final answer and we need to stop the loop
        if tool_calls is None:
            break
        for tool in tool_calls:
            tool_function = TOOL_CALL_MAP[tool.function.name]
            tool_result = tool_function(**json.loads(tool.function.arguments))
            print(f"tool result for {tool.function.name}: {tool_result}\n")
            messages.append({
                "role": "tool",
                "tool_call_id": tool.id,
                "content": tool_result,
            })
        sub_turn += 1

client = OpenAI(
    api_key=os.environ.get('DEEPSEEK_API_KEY'),
    base_url=os.environ.get('DEEPSEEK_BASE_URL'),
)

# The user starts a question
turn = 1
messages = [{
    "role": "user",
    "content": "How's the weather in Hangzhou Tomorrow"
}]
run_turn(turn, messages)

# The user starts a new question
turn = 2
messages.append({
    "role": "user",
    "content": "How's the weather in Hangzhou Tomorrow"
})
# We recommended to clear the reasoning_content in history messages so as to save network bandwidth
clear_reasoning_content(messages)
run_turn(turn, messages)
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::

In each sub-request of Turn 1, the `reasoning_content` generated during
that turn is sent to the API, allowing the model to continue its
previous reasoning. `response.choices[0].message` contains all necessary
fields for the `assistant` message, including `content`,
`reasoning_content`, and `tool_calls`. For simplicity, you can directly
append the message to the end of the messages list using the following
code:

::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
messages.append(response.choices[0].message)
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::

This line of code is equivalent to:

::: {.codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-text .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
messages.append({
    'role': 'assistant',
    'content': response.choices[0].message.content,
    'reasoning_content': response.choices[0].message.reasoning_content,
    'tool_calls': response.choices[0].message.tool_calls,
})
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::

At the beginning of Turn 2, we recommend discarding the
`reasoning_content` from previous turns to save network bandwidth:

::: {.language-python .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-python .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
clear_reasoning_content(messages)
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::

The sample output of this code is as follows:

::: {.language-bash .codeBlockContainer_pGXX .theme-code-block style="--prism-color:#393A34;--prism-background-color:#f6f8fa"}
::: codeBlockContent_CRIs
``` {.prism-code .language-bash .codeBlock_JcNi .thin-scrollbar tabindex="0" style="color:#393A34;background-color:#f6f8fa"}
Turn 1.1
reasoning_content="The user is asking about the weather in Hangzhou tomorrow. I need to get the current date first, then calculate tomorrow's date, and then call the weather API. Let me start by getting the current date."
content=''
tool_calls=[ChatCompletionMessageToolCall(id='call_00_Tcek83ZQ4fFb1RfPQnsPEE5w', function=Function(arguments='{}', name='get_date'), type='function', index=0)]
tool_result(get_date): 2025-12-01

Turn 1.2
reasoning_content='Today is December 1, 2025. Tomorrow is December 2, 2025. I need to format the date as YYYY-mm-dd: "2025-12-02". Now I can call get_weather with location Hangzhou and date 2025-12-02.'
content=''
tool_calls=[ChatCompletionMessageToolCall(id='call_00_V0Uwt4i63m5QnWRS1q1AO1tP', function=Function(arguments='{"location": "Hangzhou", "date": "2025-12-02"}', name='get_weather'), type='function', index=0)]
tool_result(get_weather): Cloudy 7~13°C

Turn 1.3
reasoning_content="I have the weather information: Cloudy with temperatures between 7 and 13°C. I should respond in a friendly, helpful manner. I'll mention that it's for tomorrow (December 2, 2025) and give the details. I can also ask if they need any other information. Let's craft the response."
content="Tomorrow (Tuesday, December 2, 2025) in Hangzhou will be **cloudy** with temperatures ranging from **7°C to 13°C**.  \n\nIt might be a good idea to bring a light jacket if you're heading out. Is there anything else you'd like to know about the weather?"
tool_calls=None

Turn 2.1
reasoning_content="The user wants clothing advice for tomorrow based on the weather in Hangzhou. I know tomorrow's weather: cloudy, 7-13°C. That's cool but not freezing. I should suggest layered clothing, maybe a jacket, long pants, etc. I can also mention that since it's cloudy, an umbrella might not be needed unless there's rain chance, but the forecast didn't mention rain. I should be helpful and give specific suggestions. I can also ask if they have any specific activities planned to tailor the advice. Let me respond."
content="Based on tomorrow's forecast of **cloudy weather with temperatures between 7°C and 13°C** in Hangzhou, here are some clothing suggestions:\n\n**Recommended outfit:**\n- **Upper body:** A long-sleeve shirt or sweater, plus a light to medium jacket (like a fleece, windbreaker, or light coat)\n- **Lower body:** Long pants or jeans\n- **Footwear:** Closed-toe shoes or sneakers\n- **Optional:** A scarf or light hat for extra warmth, especially in the morning and evening\n\n**Why this works:**\n- The temperature range is cool but not freezing, so layering is key\n- Since it's cloudy but no rain mentioned, you likely won't need an umbrella\n- The jacket will help with the morning chill (7°C) and can be removed if you warm up during the day\n\n**If you have specific plans:**\n- For outdoor activities: Consider adding an extra layer\n- For indoor/office settings: The layered approach allows you to adjust comfortably\n\nWould you like more specific advice based on your planned activities?"
tool_calls=None
```

::: buttonGroup__2VR
[![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uSWNvbl9hNnJ2Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0xOSwyMUg4VjdIMTlNMTksNUg4QTIsMiAwIDAsMCA2LDdWMjFBMiwyIDAgMCwwIDgsMjNIMTlBMiwyIDAgMCwwIDIxLDIxVjdBMiwyIDAgMCwwIDE5LDVNMTYsMUg0QTIsMiAwIDAsMCAyLDNWMTdINFYzSDE2VjFaIj48L3BhdGg+PC9zdmc+){.copyButtonIcon_a6rv}![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMjQgMjQiIGNsYXNzPSJjb3B5QnV0dG9uU3VjY2Vzc0ljb25fQmxMcSI+PHBhdGggZmlsbD0iY3VycmVudENvbG9yIiBkPSJNMjEsN0w5LDE5TDMuNSwxMy41TDQuOTEsMTIuMDlMOSwxNi4xN0wxOS41OSw1LjU5TDIxLDdaIj48L3BhdGg+PC9zdmc+){.copyButtonSuccessIcon_BlLq}]{.copyButtonIcons__UmU
aria-hidden="true"}
:::
:::
:::
:::
:::
:::

::: {.col .col--12}
:::

::: {.col .col--12}
[](/api/get-user-balance){.pagination-nav__link
.pagination-nav__link--prev}

::: pagination-nav__sublabel
Previous
:::

::: pagination-nav__label
Get User Balance
:::

[](/guides/multi_round_chat){.pagination-nav__link
.pagination-nav__link--next}

::: pagination-nav__sublabel
Next
:::

::: pagination-nav__label
Multi-round Conversation
:::
:::
:::
:::

::: {.col .col--3}
::: {.tableOfContents_QFHP .thin-scrollbar .theme-doc-toc-desktop}
-   [API Parameters](#api-parameters){.table-of-contents__link
    .toc-highlight}
-   [Multi-turn
    Conversation](#multi-turn-conversation){.table-of-contents__link
    .toc-highlight}
-   [API Example](#api-example){.table-of-contents__link .toc-highlight}
-   [Tool Calls](#tool-calls){.table-of-contents__link .toc-highlight}
    -   [Compatibility
        Notice](#compatibility-notice){.table-of-contents__link
        .toc-highlight}
    -   [Sample Code](#sample-code){.table-of-contents__link
        .toc-highlight}
:::
:::
:::
:::
:::
:::
:::
:::

::: {.container .container-fluid}
::: {.row .footer__links}
::: {.col .footer__col}
::: footer__title
WeChat Official Account
:::

-   ![WeChat
    QRcode](https://cdn.deepseek.com/official_account.jpg){width="160px"}
:::

::: {.col .footer__col}
::: footer__title
Community
:::

-   [Email![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](mailto:api-service@deepseek.com){.footer__link-item
    target="_blank" rel="noopener noreferrer"}
-   [Discord![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://discord.gg/Tc7c45Zzu5){.footer__link-item
    target="_blank" rel="noopener noreferrer"}
-   [Twitter![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://twitter.com/deepseek_ai){.footer__link-item
    target="_blank" rel="noopener noreferrer"}
:::

::: {.col .footer__col}
::: footer__title
More
:::

-   [GitHub![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTMuNSIgaGVpZ2h0PSIxMy41IiBhcmlhLWhpZGRlbj0idHJ1ZSIgdmlld2JveD0iMCAwIDI0IDI0IiBjbGFzcz0iaWNvbkV4dGVybmFsTGlua19ZSDk1Ij48cGF0aCBmaWxsPSJjdXJyZW50Q29sb3IiIGQ9Ik0yMSAxM3YxMGgtMjF2LTE5aDEydjJoLTEwdjE1aDE3di04aDJ6bTMtMTJoLTEwLjk4OGw0LjAzNSA0LTYuOTc3IDcuMDcgMi44MjggMi44MjggNi45NzctNy4wNyA0LjEyNSA0LjE3MnYtMTF6Ij48L3BhdGg+PC9zdmc+){.iconExternalLink_YH95}](https://github.com/deepseek-ai){.footer__link-item
    target="_blank" rel="noopener noreferrer"}
:::
:::

::: {.footer__bottom .text--center}
::: footer__copyright
Copyright © 2026 DeepSeek, Inc.
:::
:::
:::
:::
